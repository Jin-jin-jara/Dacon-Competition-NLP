# Dacon-Competition-NLP

Overview

올해 1월부터 7월까지 스미싱 범죄 건수는 17만6220건으로 지난해 같은 기간(14만5093건)에 비해 21.5% 증가했습니다.

특히 최근 교묘하고 지능적인 스미싱 문자 패턴으로 인해 고객들의 피해가 증가하고 있습니다. 이를 방지하기 위해 kb 금융그룹과 KISA는 데이코너들에게 도움을 요청합니다.

주최/주관
- 주최 : KB금융지주, DACON , KISA(한국인터넷진흥원)
- 주관 : DACON

Problem Statement

데이콘 금융문자 분석 경진대회에서 풀어야하는 문제는 약 26만건의 문자 데이터를 분석하여 고객들이 받은 문자가 스미싱(금융사기)문자인지 은행에서 온 정상적인 문자인지를 구별하는 것입니다. 한 가지 흥미로웠던 점은 데이콘측에서 요구한건 문자가 스미싱 문자인지 정상 문자인지 구분하는 단순한 분류(classification) 문제가 아니라 하나하나의 문자가 스미싱 문자인지 아닌지 예측값의 확률을 구해 제출할 것을 요구했다는 점입니다. 

Brief introduction to the datad

id - 각 문자가 가지고 있는 고유 구분 번호입니다.(train Data와 public_test Data의 id는 중복되지 않습니다.)
year_month - 고객이 문자를 전송 받은 년도와 월을 나타냅니다.
text - 고객이 전송 받은 문자의 내용입니다. 이번 프로젝트의 핵심적인 데이터입니다.
smishing - 해당 문자의 스미싱 여부입니다. (0 - 스미싱 아님(정상 문자), 1 -  스미싱)

text 컬럼의 데이터는 개인정보 보호를 위해, 개인정보로 간주될 수 있는 이름, 전화번호, 은행 이름, 지점명은 X 혹은 *로 필터링 되어있습니다. 

어려웠던 점 - 처음 시작하는 자연어 처리 문제였는데 처음 부딪힌 벽은 한국어였다. 많은 책들과 캐글에서 좋은 성능을 내는 코드들을 참고했는데 대부분 영어. 한국어는 교착어의 특성을 띄고, 조사, 어미가 발달했기 때문에 정확한 분석이 어려웠다. 또 한국어는 띄어쓰기에 예민하지 않기 때문에 띄어쓰기가 제대로 되지 않은 문자 데이터들이 많아서 토큰화(tokenizing) 과정이 어려웠습니다. 한국어를 분석할 때는 어근과 접사, 어미를 적절하게 나누어야하는데
  KoNLPy 같은 한국어 기반의 포스태거들은 문장분리, 토크나이즈, lemmatization, 포스태깅에 이르기까지 전 과정을 한꺼번에 수행해 줍니다.

하지만 조사, 어미가 발달한 한국어의 경우 정확한 분석이 정말 어렵습니다. 한국어는 교착어 성질을 지니는 언어이기 때문입니다. 즉 어근에 파생접사나 어미가 붙어서 단어를 이룹니다. 바꿔 말하면 한국어를 분석할 때 어근과 접사, 어미를 적절하게 나누어야 하는데, 쉽지 않다. 

단어와 형태소 분석이 자연언어처리의 기본 중 기본 
 이 작업이 신통치 않다면 이를 기반으로 하는 파싱(문장 구조 분석) 등 이후 과정의 신뢰도가 무너지게 될 겁니다. 
가장 많은 시간을 투자한건 전처리 파트였습니다. 단어와 형태소 분석이 잘 되어야 이를 기반으로한 문장 구조 분석, 토큰화, 단어 임베딩등 이후 과정이 탄탄하게 진행될 수 있다고 생각했습니다.
입력 차원들이 맞지 않아 고생.
